---
title: "MBTI"
author: "Alex Kan"
date: "February 10, 2018"
output: html_document
---

### SETUP ###
```{r setup, message = F}
### TENSORFLOW INSTALLATION 

#if (!require("tfestimators")) install.packages("tfestimators")
library(tfestimators)
#install_tensorflow()


### TIDYVERSE INSTALLATION

# if (!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)

# GLOVE DOWNLOAD 
# https://nlp.stanford.edu/projects/glove/
# GOTO: "Download pre-trained word vectors"  download glove.6B.zip 

### MBTI KAGGLE COMPETITION LINK 

# https://www.kaggle.com/datasnaek/mbti-type


# Read in full dataset, full training set, and test set 
fulldf <- read_csv("data/mbti_1.csv")
train <- read_csv("data/train.csv")
test <- read_csv("data/test_labeled.csv")

```

### EDA ###
```{r, eval = F, message = F}
#if (!require("tm")) install.packages("tm")
#if (!require("SnowballC")) install.packages("SnowballC")
#if (!require("wordcloud")) install.packages("wordcloud")

library(tm)
library(SnowballC)
library(wordcloud)

# Create new dataframes for each of the MBTI dimensions 

I <- fulldf$posts[grep(".*[I].*", fulldf$type)]
E <- fulldf$posts[grep(".*[E].*", fulldf$type)]

N <- fulldf$posts[grep(".*[N].*", fulldf$type)]
S <- fulldf$posts[grep(".*[S].*", fulldf$type)]

t <- fulldf$posts[grep(".*[T].*", fulldf$type)]
f <- fulldf$posts[grep(".*[F].*", fulldf$type)]

J <- fulldf$posts[grep(".*[J].*", fulldf$type)]
P <- fulldf$posts[grep(".*[P].*", fulldf$type)]

# Wow! It looks like introverts love these forums! 

# Def function to create and save a word cloud of top 50 most used words (minus stopwords) by commenters containing each aspect

# https://www.r-bloggers.com/building-wordclouds-in-r/ 
create_cloud <- function(x) {
   
Corpus <- Corpus(VectorSource(x))
Corpus <- tm_map(Corpus, PlainTextDocument)
Corpus <- tm_map(Corpus, removePunctuation)
Corpus <- tm_map(Corpus, removeWords, stopwords('english'))
Corpus <- tm_map(Corpus, stemDocument)
Corpus <- Corpus(VectorSource(Corpus))

path <- paste("Word Clouds/", deparse(substitute(x)), ".png", sep = "")
png(path)

wordcloud(Corpus, max.words = 50, random.order = F)
dev.off()

}

# Create word cloud for each of the eight aspects 
create_cloud(I)
create_cloud(E)
create_cloud(N)
create_cloud(S)
create_cloud(t)
create_cloud(f)
create_cloud(J)
create_cloud(P)


```

### FEATURIZATION ###
```{r}
#if (!require("ngram")) install.packages("ngram")
library(ngram)
library(stringr)

# Create ordered vector of all of the MBTI types for featurization 
types <- data.frame(unique(train$type))
types <- as.character(types[order(types[[1]]), ])
types <- tolower(types)

# Def function to create necessary features for 
featurize <- function(df) {
    
    # Define empty tibbles that will be filled within for loop
    nwords <- tibble(nwords = integer())
    words <- tibble(words = character())
    posts <- tibble(words = character())

    
    Encoding(forumposts) <- "UTF-8"
    for (i in seq_along(1:nrow(df))) {
        
        # Fill word count vector and make all characters within posts lowercase 
        words[i,1] <- as.character(unlist(df[i,3]))
        nwords[i,1] <- wordcount(unlist(words[i,1]))
        df[i,3] <- gsub(pattern = "|||", replacement = "", df[i,3])
    
    }
        # Create new features within dataframe
    
    df[4] <- nwords
    df[3] <- lapply(df[,3], str_lower_case)
    
    
    # Determine number of references to each MBTI type within each post 
    for (type in types) {
        
        numtype <- tibble(numtype = integer())
        for (i in seq_along(1:nrow(df))) {
           numtype[i,1] <- str_count(df[i, 3], type)
        }

        df[paste("num", type, sep = "")] <- numtype

    }
}


```

### tf-idf ###

```{r}

```

### MODELING ###
```{r}
set.seed(1)

# Randomly sample rows from the training set to split into the validation set 
# Validation set is sized 25% to that of the training set 

rows <- sample(1:nrow(train), size = nrow(train) * .25, replace = F)

validation <- train[rows, ]
train <- train[-rows, ]

# Create Tensorflow input function 


```


### TENSORFLOW REFERNECE ### 
https://tensorflow.rstudio.com/tfestimators/ 

```{r}
# Log reg 
```

```{r}
# Random forest 
```

```{r}
# SVM 
```

```{r}
# LDA/ QDA
```

```{r}
# Bayesian networks 
```

```{r}
# Neural net 
```


